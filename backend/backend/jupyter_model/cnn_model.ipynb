{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Flatten, Input, Embedding, TimeDistributed, Conv1D, concatenate, Lambda, Dropout\n",
    "from keras import backend as K\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_question = pd.read_csv('../data/FiQA_train_question_doc_final.tsv', sep='\\t')\n",
    "train_question = pd.read_csv('../data/FiQA_train_question_final.tsv', sep='\\t')\n",
    "train_doc = pd.read_csv('../data/FiQA_train_doc_final.tsv', sep='\\t')\n",
    "vocabulary = pd.read_csv('../data/vocabulary.csv')\n",
    "vocab_size = len(vocabulary)\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(similarity):\n",
    "    dot = lambda a, b: K.batch_dot(a, b, axes=1)\n",
    "    if similarity == 'cosine':\n",
    "            return lambda x: dot(x[0], x[1]) / K.maximum(K.sqrt(dot(x[0], x[0]) * dot(x[1], x[1])), K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_LSTM_model():\n",
    "    question = Input(shape=(max_length,), dtype='int32', name='question_base')\n",
    "    answer = Input(shape=(max_length,), dtype='int32', name='answer_base')\n",
    "\n",
    "    # add embedding layers\n",
    "    weights = np.load(self.config['initial_embed_weights'])\n",
    "    embedding = Embedding(input_dim=self.config['n_words'],\n",
    "                          output_dim=weights.shape[1],\n",
    "                          weights=[weights])\n",
    "    question_embedding = embedding(question)\n",
    "    answer_embedding = embedding(answer)\n",
    "\n",
    "    f_rnn = LSTM(141, return_sequences=True, implementation=1)\n",
    "    b_rnn = LSTM(141, return_sequences=True, implementation=1, go_backwards=True)\n",
    "\n",
    "    qf_rnn = f_rnn(question_embedding)\n",
    "    qb_rnn = b_rnn(question_embedding)\n",
    "    # question_pool = merge([qf_rnn, qb_rnn], mode='concat', concat_axis=-1)\n",
    "    question_pool = concatenate([qf_rnn, qb_rnn], axis=-1)\n",
    "\n",
    "    af_rnn = f_rnn(answer_embedding)\n",
    "    ab_rnn = b_rnn(answer_embedding)\n",
    "    # answer_pool = merge([af_rnn, ab_rnn], mode='concat', concat_axis=-1)\n",
    "    answer_pool = concatenate([af_rnn, ab_rnn], axis=-1)\n",
    "\n",
    "    # cnn\n",
    "    cnns = [Conv1D(kernel_size=kernel_size,\n",
    "                   filters=500,\n",
    "                   activation='tanh',\n",
    "                   padding='same') for kernel_size in [1, 2, 3, 5]]\n",
    "    # question_cnn = merge([cnn(question_pool) for cnn in cnns], mode='concat')\n",
    "    question_cnn = concatenate([cnn(question_pool) for cnn in cnns], axis=-1)\n",
    "    # answer_cnn = merge([cnn(answer_pool) for cnn in cnns], mode='concat')\n",
    "    answer_cnn = concatenate([cnn(answer_pool) for cnn in cnns], axis=-1)\n",
    "\n",
    "    maxpool = Lambda(lambda x: K.max(x, axis=1, keepdims=False), output_shape=lambda x: (x[0], x[2]))\n",
    "    maxpool.supports_masking = True\n",
    "    question_pool = maxpool(question_cnn)\n",
    "    answer_pool = maxpool(answer_cnn)\n",
    "    \n",
    "    #dropout layer\n",
    "    dropout = Dropout(0.2)\n",
    "    similarity = get_similarity('cosine')\n",
    "    qa_model = Lambda(similarity, output_shape=lambda _: (None, 1))([dropout(question_pool),\n",
    "                                                                     dropout(answer_pool)])\n",
    "    model = Model(inputs=[question, answer], outputs=qa_model, name='qa_model')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model():\n",
    "    question = Input(shape=(max_length,), dtype='int32', name='question_base')\n",
    "    answer = Input(shape=(max_length,), dtype='int32', name='answer_base')\n",
    "    \n",
    "    #embedding layer\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=200)\n",
    "    question_embedding = embedding(question)\n",
    "    answer_embedding = embedding(answer)\n",
    "    \n",
    "    #hidden layer\n",
    "    hidden_layer = TimeDistributed(Dense(200, activation='tanh'))\n",
    "    question_hl = hidden_layer(question_embedding)\n",
    "    answer_hl = hidden_layer(answer_embedding)\n",
    "    \n",
    "    #cnn layer\n",
    "    cnns = [Conv1D(kernel_size=kernel_size,\n",
    "                       filters=100,\n",
    "                       activation='tanh',\n",
    "                       padding='same') for kernel_size in [2, 3, 5, 7]]\n",
    "    question_cnn = concatenate([cnn(question_hl) for cnn in cnns], axis=-1)\n",
    "    answer_cnn = concatenate([cnn(answer_hl) for cnn in cnns], axis=-1)\n",
    "    \n",
    "    #max pooling layer\n",
    "    maxpool = Lambda(lambda x: K.max(x, axis=1, keepdims=False), output_shape=lambda x: (x[0], x[2]))\n",
    "    question_pool = maxpool(question_cnn)\n",
    "    answer_pool = maxpool(answer_cnn)\n",
    "    \n",
    "    #dropout layer\n",
    "    dropout = Dropout(0.2)\n",
    "    similarity = get_similarity('cosine')\n",
    "    qa_model = Lambda(similarity, output_shape=lambda _: (None, 1))([dropout(question_pool),\n",
    "                                                                     dropout(answer_pool)])\n",
    "    model = Model(inputs=[question, answer], outputs=qa_model, name='qa_model')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "#     qdic = train_question.set_index('qid').T.to_dict('list')\n",
    "#     docdic = train_doc.set_index('docid').T.to_dict('list')\n",
    "\n",
    "    #question id and the corresponding doc id\n",
    "    question_id_list = train_doc_question['qid']\n",
    "    doc_id_list = train_doc_question['docid']\n",
    "\n",
    "    questions = []\n",
    "    good_answers = []\n",
    "    bad_answers = []\n",
    "    train_doc_list = train_doc.dropna(axis=0, how='any')\n",
    "    train_doc_list = list(train_doc_list['doc'])\n",
    "    \n",
    "    for i in range(0, len(train_doc_question)):\n",
    "        doc_value = train_doc[train_doc.docid == doc_id_list[i]]['doc'].values[0]\n",
    "        if doc_value == doc_value:\n",
    "            question = train_question[train_question.qid == question_id_list[i]]['question'].values[0]\n",
    "            questions.append(question)\n",
    "            good_answers.append(doc_value)\n",
    "            bad_answers.append(random.choice(train_doc_list))\n",
    "\n",
    "    return [questions, good_answers, bad_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, good_answers, bad_answers = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_qs = [one_hot(d, vocab_size) for d in questions]\n",
    "padded_qs = pad_sequences(encoded_qs, maxlen=max_length, padding='post')\n",
    "\n",
    "encoded_good_answers = [one_hot(d, vocab_size) for d in good_answers]\n",
    "padded_good_answers = pad_sequences(encoded_good_answers, maxlen=max_length, padding='post')\n",
    "\n",
    "encoded_bad_answers = [one_hot(d, vocab_size) for d in bad_answers]\n",
    "padded_bad_answers = pad_sequences(encoded_bad_answers, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "question_base (InputLayer)      (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "answer_base (InputLayer)        (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 200)     11982600    question_base[0][0]              \n",
      "                                                                 answer_base[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 100, 200)     40200       embedding_2[0][0]                \n",
      "                                                                 embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 100, 100)     40100       time_distributed_2[0][0]         \n",
      "                                                                 time_distributed_2[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 100, 100)     60100       time_distributed_2[0][0]         \n",
      "                                                                 time_distributed_2[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 100, 100)     100100      time_distributed_2[0][0]         \n",
      "                                                                 time_distributed_2[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 100, 100)     140100      time_distributed_2[0][0]         \n",
      "                                                                 time_distributed_2[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 100, 400)     0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 100, 400)     0           conv1d_5[1][0]                   \n",
      "                                                                 conv1d_6[1][0]                   \n",
      "                                                                 conv1d_7[1][0]                   \n",
      "                                                                 conv1d_8[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 400)          0           concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400)          0           lambda_4[0][0]                   \n",
      "                                                                 lambda_4[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           dropout_2[0][0]                  \n",
      "                                                                 dropout_2[1][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,363,200\n",
      "Trainable params: 12,363,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "question_base (InputLayer)      (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "good_answers_base (InputLayer)  (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bad_answers_base (InputLayer)   (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "qa_model (Model)                (None, 1)            12363200    question_base[0][0]              \n",
      "                                                                 good_answers_base[0][0]          \n",
      "                                                                 question_base[0][0]              \n",
      "                                                                 bad_answers_base[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           qa_model[1][0]                   \n",
      "                                                                 qa_model[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 12,363,200\n",
      "Trainable params: 12,363,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define the input of the model\n",
    "q_input = Input(shape=(max_length,), dtype='int32', name='question_base')\n",
    "good_answers_input = Input(shape=(max_length,), dtype='int32', name='good_answers_base')\n",
    "bad_answers_input = Input(shape=(max_length,), dtype='int32', name='bad_answers_base')\n",
    "\n",
    "# get the cnn model\n",
    "model = CNN_model()\n",
    "model.summary()\n",
    "good_similarity = model([q_input, good_answers_input])\n",
    "bad_similarity = model([q_input, bad_answers_input])\n",
    "\n",
    "#define the loss function, simialrity with the good_answers \n",
    "#need to be larger while similarity with the bad_answers need to be smaller\n",
    "loss = Lambda(lambda x: K.relu(0.009 - x[0] + x[1]),\n",
    "                      output_shape=lambda x: x[0])([good_similarity, bad_similarity])\n",
    "training_model = Model(inputs=[q_input, good_answers_input, bad_answers_input], outputs=loss,\n",
    "                                name='training_model')\n",
    "\n",
    "training_model.compile(loss=lambda y_true, y_pred: y_pred, optimizer='adam')\n",
    "training_model.summary()\n",
    "\n",
    "prediction_model = Model(inputs=[q_input, good_answers_input], outputs=good_similarity,\n",
    "                                      name='prediction_model')\n",
    "prediction_model.compile(loss=lambda y_true, y_pred: y_pred, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "17072/17072 [==============================] - 502s 29ms/step - loss: 0.0018\n",
      "Epoch 2/5\n",
      "17072/17072 [==============================] - 499s 29ms/step - loss: 0.0014\n",
      "Epoch 3/5\n",
      "17072/17072 [==============================] - 557s 33ms/step - loss: 0.0012\n",
      "Epoch 4/5\n",
      "17072/17072 [==============================] - 497s 29ms/step - loss: 0.0011\n",
      "Epoch 5/5\n",
      "17072/17072 [==============================] - 486s 28ms/step - loss: 8.1407e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12017d710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = np.zeros(shape=(len(encoded_qs),)) # doesn't get used\n",
    "\n",
    "training_model.fit([padded_qs, padded_good_answers, padded_bad_answers], y, batch_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.save('../model/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model.save('../model/predict_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91682464],\n",
       "       [0.9243847 ],\n",
       "       [0.9281581 ],\n",
       "       ...,\n",
       "       [0.94948924],\n",
       "       [0.94622576],\n",
       "       [0.9294157 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model.predict([padded_qs, padded_good_answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91746026],\n",
       "       [0.918111  ],\n",
       "       [0.9249023 ],\n",
       "       ...,\n",
       "       [0.93947494],\n",
       "       [0.94490683],\n",
       "       [0.9210839 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model.predict([padded_qs, padded_bad_answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = train_doc.dropna()\n",
    "select_qs = [train_question['question'][0]] * len(train_doc)\n",
    "select_encoded_qs = [one_hot(d, vocab_size) for d in select_qs]\n",
    "select_padded_qs = pad_sequences(select_encoded_qs, maxlen=max_length, padding='post')\n",
    "select_answers = train_doc['doc'].values \n",
    "select_encoded_answers = [one_hot(d, vocab_size) for d in select_answers]\n",
    "select_padded_answers = pad_sequences(select_encoded_answers, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_result = prediction_model.predict([select_padded_qs, select_padded_answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 'What is considered a business expense on a business trip?'\n",
      " \"Nov 8 '11 at 15:14\"]\n",
      "0\n",
      "What is considered a business expense on a business trip?\n",
      "      docid  probability\n",
      "4881  18850  [0.3935241]\n"
     ]
    }
   ],
   "source": [
    "result = DataFrame(data={'probability': list(select_result), 'docid': train_doc['docid'].values})\n",
    "result = result.sort_values('probability', ascending=False)\n",
    "result =  result.reset_index(drop=True)\n",
    "\n",
    "print(train_question.values[0])\n",
    "print(train_question['qid'][0])\n",
    "print(train_question['question'][0])\n",
    "print(result[result.docid == 18850])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  qid  docid\n",
      "0   0    0  18850\n"
     ]
    }
   ],
   "source": [
    "print(train_doc_question[train_doc_question.qid == train_question['qid'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
